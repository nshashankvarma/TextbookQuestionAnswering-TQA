{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vH65VANLKs6K"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import sys\n",
        "test_json = pd.read_json(\"/content/drive/MyDrive/tqa_v1_train.json\")\n",
        "\n",
        "cols = [\"text\",\"question\",\"answer\"]\n",
        "data_list=[]\n",
        "for index,row in list(test_json.iterrows()):\n",
        "  try:\n",
        "    text = row['adjunctTopics']['Introduction']['content']['text'] + row['adjunctTopics']['Lesson Summary']['content']['text']\n",
        "    questions = row['questions']['nonDiagramQuestions']\n",
        "    for qid, qs in list(questions.items()):\n",
        "        temp=[]\n",
        "        question = qs['beingAsked']['processedText']\n",
        "        answer = qs['answerChoices'][qs['correctAnswer']['processedText']]['processedText']\n",
        "        temp.append(text)\n",
        "        temp.append(question)\n",
        "        temp.append(answer)\n",
        "        data_list.append(temp)\n",
        "  except:\n",
        "    continue\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "new_df = pd.DataFrame(data_list, columns=cols)\n",
        "new_df.to_csv(\"TQA_data.csv\", index=False)"
      ],
      "metadata": {
        "id": "nzjraP01Tyru",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "36a97938-5f06-4464-e411-39826f2c6492"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-20b663426d85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnew_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnew_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TQA_data.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data_list' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "new_df=pd.read_csv('/content/drive/MyDrive/CNN-TQA/TQA_data.csv')\n",
        "len(new_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWzjVMN_SdKT",
        "outputId": "daf0e0a8-2467-4a2c-916f-7a071223c0c8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4894"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import BertForQuestionAnswering\n",
        "from transformers import BertTokenizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VY4DhwPUeS0",
        "outputId": "d5733f5d-36f4-4361-8fd6-2ca49eedc684"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
      ],
      "metadata": {
        "id": "_UgJZ16oVGuz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_num = np.random.randint(0,len(new_df))\n",
        "question = new_df[\"question\"][random_num]\n",
        "text = new_df[\"text\"][random_num]"
      ],
      "metadata": {
        "id": "vnb_Nwg9VOWa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenizer.encode(question, text)\n",
        "print(\"The input has a total of {} tokens.\".format(len(input_ids)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1l7vv_EVPlI",
        "outputId": "c4ed6d7b-0edb-4f8b-9010-0f5f14f65f7e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The input has a total of 237 tokens.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
        "for token, id in zip(tokens, input_ids):\n",
        "    print('{:8}{:8,}'.format(token,id))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzxyG61bVQLZ",
        "outputId": "68a136e5-31cb-43ba-8e84-86c4e36aee90"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS]        101\n",
            "how        2,129\n",
            "many       2,116\n",
            "groups     2,967\n",
            "are        2,024\n",
            "there      2,045\n",
            "in         1,999\n",
            "men        2,273\n",
            "##del      9,247\n",
            "##ee       4,402\n",
            "##vs      15,088\n",
            "periodic  15,861\n",
            "table      2,795\n",
            "?          1,029\n",
            "[SEP]        102\n",
            "scientists   6,529\n",
            "first      2,034\n",
            "started    2,318\n",
            "looking    2,559\n",
            "for        2,005\n",
            "a          1,037\n",
            "way        2,126\n",
            "to         2,000\n",
            "organize  10,939\n",
            "the        1,996\n",
            "elements   3,787\n",
            "in         1,999\n",
            "the        1,996\n",
            "1700      16,601\n",
            "##s        2,015\n",
            ".          1,012\n",
            "they       2,027\n",
            "were       2,020\n",
            "trying     2,667\n",
            "to         2,000\n",
            "find       2,424\n",
            "a          1,037\n",
            "method     4,118\n",
            "to         2,000\n",
            "group      2,177\n",
            "together   2,362\n",
            "elements   3,787\n",
            "with       2,007\n",
            "similar    2,714\n",
            "properties   5,144\n",
            ".          1,012\n",
            "no         2,053\n",
            "one        2,028\n",
            "could      2,071\n",
            "come       2,272\n",
            "up         2,039\n",
            "with       2,007\n",
            "a          1,037\n",
            "good       2,204\n",
            "solution   5,576\n",
            ".          1,012\n",
            "it         2,009\n",
            "wasn       2,347\n",
            "##t        2,102\n",
            "until      2,127\n",
            "the        1,996\n",
            "1860s     15,914\n",
            "that       2,008\n",
            "a          1,037\n",
            "successful   3,144\n",
            "method     4,118\n",
            "was        2,001\n",
            "devised   14,917\n",
            ".          1,012\n",
            "it         2,009\n",
            "was        2,001\n",
            "developed   2,764\n",
            "by         2,011\n",
            "a          1,037\n",
            "russian    2,845\n",
            "chemist   15,535\n",
            "named      2,315\n",
            "dmitri    28,316\n",
            "men        2,273\n",
            "##del      9,247\n",
            "##ee       4,402\n",
            "##v        2,615\n",
            ".          1,012\n",
            "he         2,002\n",
            "is         2,003\n",
            "pictured  15,885\n",
            "in         1,999\n",
            "figure     3,275\n",
            "6          1,020\n",
            ".          1,012\n",
            "1          1,015\n",
            ".          1,012\n",
            "you        2,017\n",
            "can        2,064\n",
            "learn      4,553\n",
            "more       2,062\n",
            "about      2,055\n",
            "him        2,032\n",
            "and        1,998\n",
            "his        2,010\n",
            "work       2,147\n",
            "at         2,012\n",
            "this       2,023\n",
            "ur        24,471\n",
            "##l        2,140\n",
            ":          1,024\n",
            "http       8,299\n",
            ":          1,024\n",
            "/          1,013\n",
            "/          1,013\n",
            "videos     6,876\n",
            ".          1,012\n",
            "how        2,129\n",
            "##st       3,367\n",
            "##uf      16,093\n",
            "##f        2,546\n",
            "##works    9,316\n",
            ".          1,012\n",
            "com        4,012\n",
            "/          1,013\n",
            "men        2,273\n",
            "##del      9,247\n",
            "##ee       4,402\n",
            "##v        2,615\n",
            "developed   2,764\n",
            "the        1,996\n",
            "first      2,034\n",
            "periodic  15,861\n",
            "table      2,795\n",
            "of         1,997\n",
            "the        1,996\n",
            "elements   3,787\n",
            "in         1,999\n",
            "1869       7,845\n",
            ".          1,012\n",
            "he         2,002\n",
            "organized   4,114\n",
            "the        1,996\n",
            "elements   3,787\n",
            "by         2,011\n",
            "increasing   4,852\n",
            "atomic     9,593\n",
            "mass       3,742\n",
            ".          1,012\n",
            "he         2,002\n",
            "used       2,109\n",
            "his        2,010\n",
            "table      2,795\n",
            "to         2,000\n",
            "predict   16,014\n",
            "unknown    4,242\n",
            "elements   3,787\n",
            ".          1,012\n",
            "these      2,122\n",
            "were       2,020\n",
            "later      2,101\n",
            "discovered   3,603\n",
            ".          1,012\n",
            "the        1,996\n",
            "modern     2,715\n",
            "periodic  15,861\n",
            "table      2,795\n",
            "is         2,003\n",
            "based      2,241\n",
            "on         2,006\n",
            "atomic     9,593\n",
            "number     2,193\n",
            ".          1,012\n",
            "elements   3,787\n",
            "in         1,999\n",
            "each       2,169\n",
            "period     2,558\n",
            "go         2,175\n",
            "from       2,013\n",
            "metals    11,970\n",
            "on         2,006\n",
            "the        1,996\n",
            "left       2,187\n",
            "to         2,000\n",
            "metal      3,384\n",
            "##loid    27,710\n",
            "##s        2,015\n",
            "and        1,998\n",
            "then       2,059\n",
            "non        2,512\n",
            "##met     11,368\n",
            "##als      9,777\n",
            "on         2,006\n",
            "the        1,996\n",
            "right      2,157\n",
            ".          1,012\n",
            "within     2,306\n",
            "groups     2,967\n",
            ",          1,010\n",
            "elements   3,787\n",
            "have       2,031\n",
            "similar    2,714\n",
            "properties   5,144\n",
            ".          1,012\n",
            "starts     4,627\n",
            "##e        2,063\n",
            "##q        4,160\n",
            "girl       2,611\n",
            "in         1,999\n",
            "red        2,417\n",
            "shirt      3,797\n",
            "and        1,998\n",
            "black      2,304\n",
            "hat        6,045\n",
            "is         2,003\n",
            "sitting    3,564\n",
            "on         2,006\n",
            "the        1,996\n",
            "camera     4,950\n",
            "ends       4,515\n",
            "##e        2,063\n",
            "##q        4,160\n",
            "##star    14,117\n",
            "##ts       3,215\n",
            "##e        2,063\n",
            "##q        4,160\n",
            "girl       2,611\n",
            "in         1,999\n",
            "red        2,417\n",
            "shirt      3,797\n",
            "and        1,998\n",
            "black      2,304\n",
            "hat        6,045\n",
            "is         2,003\n",
            "sitting    3,564\n",
            "on         2,006\n",
            "the        1,996\n",
            "camera     4,950\n",
            "ends       4,515\n",
            "##e        2,063\n",
            "##q        4,160\n",
            "[SEP]        102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#first occurence of [SEP] token\n",
        "sep_idx = input_ids.index(tokenizer.sep_token_id)\n",
        "print(\"SEP token index: \", sep_idx)#number of tokens in segment A (question) - this will be one more than the sep_idx as the index in Python starts from 0\n",
        "num_seg_a = sep_idx+1\n",
        "print(\"Number of tokens in segment A: \", num_seg_a)#number of tokens in segment B (text)\n",
        "num_seg_b = len(input_ids) - num_seg_a\n",
        "print(\"Number of tokens in segment B: \", num_seg_b)#creating the segment ids\n",
        "segment_ids = [0]*num_seg_a + [1]*num_seg_b#making sure that every input token has a segment id\n",
        "assert len(segment_ids) == len(input_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiP0aMuoVRXw",
        "outputId": "d2bf8eb1-3ef5-47f0-aa8b-fc5b00e0e555"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SEP token index:  14\n",
            "Number of tokens in segment A:  15\n",
            "Number of tokens in segment B:  222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#token input_ids to represent the input and token segment_ids to differentiate our segments - question and text\n",
        "output = model(torch.tensor([input_ids]),  token_type_ids=torch.tensor([segment_ids]))"
      ],
      "metadata": {
        "id": "pKQbcoGNVUYB"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tokens with highest start and end scores\n",
        "answer_start = torch.argmax(output.start_logits)\n",
        "answer_end = torch.argmax(output.end_logits)\n",
        "if answer_end >= answer_start:\n",
        "    answer = \" \".join(tokens[answer_start:answer_end+1])\n",
        "else:\n",
        "    print(\"I am unable to find the answer to this question. Can you please ask another question?\")\n",
        "    \n",
        "print(\"\\nQuestion:\\n{}\".format(question.capitalize()))\n",
        "print(\"\\nAnswer:\\n{}.\".format(answer.capitalize()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fz10WMg2VVl4",
        "outputId": "d95ccab7-b08c-4fd0-ea42-17b81f99e8ed"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Question:\n",
            "What team does he play for?\n",
            "\n",
            "Answer:\n",
            "6 . 1 . you can learn more about him and his work at this ur ##l : http : / / videos . how ##st ##uf ##f ##works . com / men ##del ##ee ##v developed the first periodic table of the elements in 1869 . he organized the elements by increasing atomic mass . he used his table to predict unknown elements . these were later discovered . the modern periodic table is based on atomic number . elements in each period go from metals on the left to metal ##loid ##s and then non ##met ##als on the right . within groups , elements have similar properties.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer = tokens[answer_start]\n",
        "for i in range(answer_start+1, answer_end+1):\n",
        "    if tokens[i][0:2] == \"##\":\n",
        "        answer += tokens[i][2:]\n",
        "    else:\n",
        "        answer += \" \" + tokens[i]"
      ],
      "metadata": {
        "id": "7lTKdF1-VWw_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def question_answer(question, text):\n",
        "    \n",
        "    #tokenize question and text as a pair\n",
        "    input_ids = tokenizer.encode(question, text)\n",
        "    \n",
        "    #string version of tokenized ids\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
        "    \n",
        "    #segment IDs\n",
        "    #first occurence of [SEP] token\n",
        "    sep_idx = input_ids.index(tokenizer.sep_token_id)    #number of tokens in segment A (question)\n",
        "    num_seg_a = sep_idx+1    #number of tokens in segment B (text)\n",
        "    num_seg_b = len(input_ids) - num_seg_a\n",
        "    \n",
        "    #list of 0s and 1s for segment embeddings\n",
        "    segment_ids = [0]*num_seg_a + [1]*num_seg_b    \n",
        "    assert len(segment_ids) == len(input_ids)\n",
        "    \n",
        "    #model output using input_ids and segment_ids\n",
        "    output = model(torch.tensor([input_ids]), token_type_ids=torch.tensor([segment_ids]))\n",
        "    \n",
        "    #reconstructing the answer\n",
        "    answer_start = torch.argmax(output.start_logits)\n",
        "    answer_end = torch.argmax(output.end_logits)\n",
        "    if answer_end >= answer_start:\n",
        "      answer = tokens[answer_start]\n",
        "      for i in range(answer_start+1, answer_end+1):\n",
        "          if tokens[i][0:2] == \"##\":\n",
        "              answer += tokens[i][2:]\n",
        "          else:\n",
        "              answer += \" \" + tokens[i]\n",
        "                \n",
        "    if answer.startswith(\"[CLS]\"):\n",
        "        answer = \"Unable to find the answer to your question.\"\n",
        "    \n",
        "    print(\"\\nPredicted answer:\\n{}\".format(answer.capitalize()))"
      ],
      "metadata": {
        "id": "PMhEUmvzVYFO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = input(\"Please enter your text: \\n\")\n",
        "question = input(\"\\nPlease enter your question: \\n\")\n",
        "while True:\n",
        "    question_answer(question, text)\n",
        "    \n",
        "    flag = True\n",
        "    flag_N = False\n",
        "    \n",
        "    while flag:\n",
        "        response = input(\"\\nDo you want to ask another question based on this text (Y/N)? \")\n",
        "        if response[0] == \"Y\":\n",
        "            question = input(\"\\nPlease enter your question: \\n\")\n",
        "            flag = False\n",
        "        elif response[0] == \"N\":\n",
        "            print(\"\\nBye!\")\n",
        "            flag = False\n",
        "            flag_N = True\n",
        "            \n",
        "    if flag_N == True:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjgIHviLVY-5",
        "outputId": "6b12b3ea-a92f-45f0-c032-2acf051a399d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter your text: \n",
            "Virat Kohli is an Indian international cricketer and former captain of the India national cricket team. Widely regarded as one of the greatest batsmen of all time, Kohli plays as a right-handed batsman for Royal Challengers Bangalore in the Indian Premier League and for Delhi in domestic cricket.\n",
            "\n",
            "Please enter your question: \n",
            "What team does he play for?\n",
            "\n",
            "Predicted answer:\n",
            "Royal challengers bangalore\n",
            "\n",
            "Do you want to ask another question based on this text (Y/N)? N\n",
            "\n",
            "Bye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fINm8GvyVZBJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}